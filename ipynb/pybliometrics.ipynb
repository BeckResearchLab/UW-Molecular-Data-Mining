{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is meant to prototype a script that can find the publication PII identification numbers automatically for a query into the science direct database.\n",
    "\n",
    "# To test queries, go to https://www.scopus.com/search/form.uri?display=advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The link to elsevier active journals link: https://www.elsevier.com/__data/promis_misc/sd-content/journals/jnlactivesubject.xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybliometrics\n",
    "from pybliometrics.scopus import ScopusSearch\n",
    "from pybliometrics.scopus.exception import Scopus429Error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import multiprocessing\n",
    "from os import system, name\n",
    "import json\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from pybliometrics.scopus import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals for the algorithm\n",
    "\n",
    "List of things by which the algorithm will parse searches:\n",
    "\n",
    "1. Year\n",
    "2. Journal\n",
    "3. Keyword search\n",
    "\n",
    "Here is an example search syntax: `s = ScopusSearch('FIRSTAUTH ( kitchin  j.r. )')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following method creates a dataframe that only contains journals mentioning certain keywords in their 'Full_Category' column. \n",
    "### It still needs work on user friendlyness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "els_jpath = 'https://www.elsevier.com/__data/promis_misc/sd-content/journals/jnlactivesubject.xls'\n",
    "\n",
    "def make_jlist(jlist_url):\n",
    "    \"\"\"\n",
    "    This method creates a dataframe of relevant journals to query. The dataframe contains two columns:\n",
    "    (1) The names of the Journals\n",
    "    (2) The issns of the Journals\n",
    "    \"\"\"\n",
    "    \n",
    "    # This creates a dataframe of the active journals and their subjects from elsevier\n",
    "    active_journals = pd.read_excel(jlist_url)\n",
    "    active_journals.rename(columns = {'Display Category Full Name':'Full_Category','Full Title':'Journal_Title'}, inplace = True)\n",
    "    \n",
    "    active_journals.Full_Category = active_journals.Full_Category.str.lower() # lowercase topics for searching\n",
    "    active_journals = active_journals.drop_duplicates(subset = 'Journal_Title') # drop any duplicate journals\n",
    "    active_journals = shuffle(active_journals,random_state = 42) \n",
    "\n",
    "\n",
    "    # journal_strings is currently unused\n",
    "    # The set of default strings that will be used to sort which journals we want\n",
    "    journal_strings = ['chemistry','energy','molecular','atomic','chemical','biochem'\n",
    "                      ,'organic','polymer','chemical engineering','biotech','coloid']\n",
    "\n",
    "    # making this an easier command to type\n",
    "    name = active_journals['Full_Category'].str.contains\n",
    "\n",
    "\n",
    "    # desired keywords\n",
    "    # new dataframe full of only journals who's topic description contained the\n",
    "    active_journals= active_journals[name('polymer') | name('chemistry') | name('energy')| \n",
    "                                     name('molecular') | name('colloid') | name('biochem')| \n",
    "                                     name('organic') | name('biotech') | name('chemical')]\n",
    "    \n",
    "    journal_frame = active_journals[['Journal_Title','ISSN']]\n",
    "    \n",
    "    return journal_frame\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_stdout(): \n",
    "    os.system('cls' if os.name == 'nt' else 'clear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_list = make_jlist(els_jpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal_Title</th>\n",
       "      <th>ISSN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>Gene: X</td>\n",
       "      <td>25901583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3917</td>\n",
       "      <td>Journal of Infection</td>\n",
       "      <td>01634453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6729</td>\n",
       "      <td>Thermochimica Acta</td>\n",
       "      <td>00406031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6587</td>\n",
       "      <td>Surface Science</td>\n",
       "      <td>00396028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3554</td>\n",
       "      <td>Journal of Colloid and Interface Science</td>\n",
       "      <td>00219797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Journal_Title      ISSN\n",
       "2580                                   Gene: X  25901583\n",
       "3917                      Journal of Infection  01634453\n",
       "6729                        Thermochimica Acta  00406031\n",
       "6587                           Surface Science  00396028\n",
       "3554  Journal of Colloid and Interface Science  00219797"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following method builds the keyword search portion of a query. There is an example below that can be copy-pasted into the Scopus advanced Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_search_terms(kwds):\n",
    "    \"\"\"\n",
    "    This builds the keyword search portion of the query string. \n",
    "    \"\"\"\n",
    "    tak = \"\"\n",
    "    for i in range(len(kwds)):\n",
    "        if i != len(kwds)-1:\n",
    "            tak += kwds[i] + ' OR '\n",
    "        else:\n",
    "            tak += kwds[i] + ' '\n",
    "    \n",
    "    return tak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following method builds the entiry query to be put into pybliometrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a model test query \n",
    "# test = search(verbose = True, query = 'polymer OR organic OR molecular AND PUBYEAR IS 2019 AND ISSN(00404020)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query_dict(term_list,issn_list,year_list):\n",
    "    \"\"\"\n",
    "    This method takes the list of journals and creates a nested dictionary\n",
    "    containing all accessible queries, in each year, for each journal,\n",
    "    for a given keyword search on sciencedirect.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    term_list(list, required): the list of search terms looked for in papers by the api.\n",
    "    \n",
    "    issn_list(list, required): the list of journal issn's to be queried. Can be created by getting the '.values'\n",
    "    of a 'journal_list' dataframe that has been created from the 'make_jlist' method.\n",
    "    \n",
    "    year_list(list, required): the list of years which will be searched through\n",
    "    \n",
    "    \"\"\"\n",
    "    search_terms = build_search_terms(term_list)\n",
    "    dict1 = {}\n",
    "    \n",
    "    for issn in issn_list:\n",
    "        \n",
    "        issn_terms = ' AND ISSN(' + issn + ')'\n",
    "        dict2 = {}\n",
    "        \n",
    "        for year in year_list:\n",
    "            \n",
    "            year_terms = \"AND PUBYEAR IS \" + str(year)\n",
    "            querystring = search_terms + year_terms + issn_terms\n",
    "\n",
    "            dict2[year] = querystring\n",
    "\n",
    "        dict1[issn] = dict2\n",
    "\n",
    "    return dict1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_list = ['polymer','organic','molecular','molecule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'polymer OR organic OR molecular OR molecule AND PUBYEAR IS 2015 AND ISSN(00404020)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of how to use the dictionary builder\n",
    "issn_list = journal_list['ISSN'].values\n",
    "dictionary = build_query_dict(term_list,issn_list,range(1995,2021))\n",
    "dictionary['00404020'][2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newkey = fresh_keys[2]\n",
    "config[\"Authentication\"][\"APIKey\"] = newkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading results for query \"polymer OR organic OR molecular OR molecule AND PUBYEAR IS 2003 AND ISSN(00404020)\":\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n"
     ]
    }
   ],
   "source": [
    "test = ScopusSearch(verbose=True, query = dictionary['00404020'][2003])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(test.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is a method to clear the cache. Doesn't matter too much because 1.1 million pubs stored in cache only took 2 GB of memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_cache(cache_path):\n",
    "    \"\"\"\n",
    "    Be very careful with this method. It can delete your entire computer if you let it. \n",
    "    \"\"\"\n",
    "    \n",
    "    # if the cache path contains the proper substring, and if the files we are deleting are of the propper length, delete the files\n",
    "    \n",
    "    if '.scopus/scopus_search/' in cache_path:\n",
    "        for file in os.listdir(cache_path):\n",
    "            \n",
    "            # Making sure the deleted files match the standard length of pybliometrics cache output\n",
    "            if len(file) == len('8805245317ccb15059e3cfa219be2dd4'):\n",
    "                os.remove(cache_path + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The method below loops through the entire journal list and collects article metadata, including PII"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things we probably want to just grab because we have them:\n",
    "1. Author names\n",
    "2. Author keywords\n",
    "3. Cited by count\n",
    "4. title\n",
    "5. PII\n",
    "6. DOI\n",
    "7. Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cell below here is test code for making a key replacement method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_piis(term_list, journal_frame, year_list, cache_path, output_path,keymaster=False,fresh_keys=None,config_path='/Users/DavidCJ/.scopus/config.ini'):\n",
    "    \"\"\"\n",
    "    This should be a standalone method that recieves a list of journals (issns), a keyword search,\n",
    "    an output path and a path to clear the cache. It should be mappable to multiple parallel processes. \n",
    "    \"\"\"\n",
    "    if output_path[-1] is not '/':\n",
    "        raise Exception('Output file path must end with /')\n",
    "    \n",
    "    if '.scopus/scopus_search' not in cache_path:\n",
    "        raise Exception('Cache path is not a sub-directory of the scopus_search. Make sure cache path is correct.')\n",
    "    \n",
    "        \n",
    "    # Two lists who's values correspond to each other    \n",
    "    issn_list = journal_frame['ISSN'].values\n",
    "    journal_list = journal_frame['Journal_Title'].values\n",
    "    \n",
    "    # Find and replaces slashes and spaces in names for file storage purposes\n",
    "    for j in range(len(journal_list)):\n",
    "        if ':' in journal_list[j]:\n",
    "            journal_list[j] = journal_list[j].replace(':','')\n",
    "        elif '/' in journal_list[j]:\n",
    "            journal_list[j] = journal_list[j].replace('/','_')\n",
    "        \n",
    "        elif ' ' in journal_list[j]:\n",
    "            journal_list[j] = journal_list[j].replace(' ','_')\n",
    "    \n",
    "            \n",
    "    \n",
    "    # Build the dictionary that can be used to sequentially query elsevier for different journals and years\n",
    "    query_dict = build_query_dict(term_list,issn_list,year_list)\n",
    "    \n",
    "    # Must write to memory, clear cache, and clear a dictionary upon starting every new journal\n",
    "    for i in range(len(issn_list)):\n",
    "        # At the start of every year, clear the standard output screen\n",
    "        clear_stdout()\n",
    "        #clear_cache(cache_path) # only want clear_cache() uncommented if we are NOT paralellizing. Multiple processes trying to clear the same cache is ugly.\n",
    "        paper_counter = 0\n",
    "\n",
    "        issn_dict = {}\n",
    "        for j in range(len(year_list)):\n",
    "            \n",
    "            # for every year in every journal, query the keywords\n",
    "            print(f'{journal_list[i]} in {year_list[j]}.')\n",
    "            \n",
    "            # Want the sole 'keymaster' process to handle 429 responses by swapping the key. \n",
    "            if keymaster:\n",
    "                try:\n",
    "                    query_results = ScopusSearch(verbose = True,query = query_dict[issn_list[i]][year_list[j]])\n",
    "                except:\n",
    "                    print('entered scopus 429 error loop... replacing key')\n",
    "                    newkey = fresh_keys.pop()\n",
    "                    config[\"Authentication\"][\"APIKey\"] = newkey\n",
    "                    time.sleep(5)\n",
    "                    query_results = ScopusSearch(verbose = True,query = query_dict[issn_list[i]][year_list[j]])   \n",
    "            # If this process isn't the keymaster, try a query. \n",
    "            # If it excepts, wait a few seconds for keymaster to replace key and try again.\n",
    "            else:\n",
    "                try:\n",
    "                    query_results = ScopusSearch(verbose = True,query = query_dict[issn_list[i]][year_list[j]])\n",
    "                except:\n",
    "                    time.sleep(15)\n",
    "                    query_results = ScopusSearch(verbose = True,query = query_dict[issn_list[i]][year_list[j]])\n",
    "            \n",
    "            \n",
    "            # store relevant information from the results into a dictionary pertaining to that query\n",
    "            year_dict = {}\n",
    "            if query_results.results is not None:\n",
    "                # some of the query results might be of type None \n",
    "                \n",
    "                \n",
    "                for k in range(len(query_results.results)):\n",
    "                    paper_counter += 1\n",
    "                    \n",
    "                    result_dict = {}\n",
    "                    result = query_results.results[k]\n",
    "\n",
    "                    result_dict['pii'] = result.pii\n",
    "                    result_dict['doi'] = result.doi\n",
    "                    result_dict['title'] = result.title\n",
    "                    result_dict['num_authors'] = result.author_count\n",
    "                    result_dict['authors'] = result.author_names\n",
    "                    result_dict['description'] = result.description\n",
    "                    result_dict['citation_count'] = result.citedby_count\n",
    "                    result_dict['keywords'] = result.authkeywords\n",
    "                    \n",
    "                    year_dict[k] = result_dict\n",
    "\n",
    "                # Store all of the results for this year in the dictionary containing to a certain journal\n",
    "                issn_dict[year_list[j]] = year_dict\n",
    "            else:\n",
    "                # if it was a None type, we will just store the empty dictionary as json\n",
    "                issn_dict[year_list[j]] = year_dict\n",
    "        \n",
    "        \n",
    "        # Store all of the results for this journal in a folder as json file\n",
    "        os.mkdir(f'{output_path}{journal_list[i]}')\n",
    "        with open(f'{output_path}{journal_list[i]}/{journal_list[i]}.json','w') as file:\n",
    "            json.dump(issn_dict, file)\n",
    "        \n",
    "        with open(f'{output_path}{journal_list[i]}/{journal_list[i]}.txt','w') as file2:\n",
    "            file2.write(f'This file contains {paper_counter} publications.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = '/Users/DavidCJ/.scopus/scopus_search/COMPLETE/'\n",
    "term_list = ['polymer','organic','molecular','property']\n",
    "journal_frame = make_jlist(els_jpath)\n",
    "\n",
    "# the below command worked well for a single process\n",
    "#get_piis(term_list,journal_frame,range(1995,2021),cache_path=cache_path,output_path = '/Users/DavidJuergens/Desktop/pyblio_test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi process cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2 = np.array_split(journal_frame,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_keys = ['5c3e44d3231b7ef83bbd46a1fca5fe0d','5fdac5c4056d99b0afcca6dfa7a846ae','2964abe851124885c54e2ae3b83acdd1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = multiprocessing.Process(target = get_piis, args = [term_list,df1,range(1995,2021),cache_path,'/Volumes/My Passport/Davids Stuff/pyblio_test3/',True,fresh_keys])\n",
    "p2 = multiprocessing.Process(target = get_piis, args = [term_list,df2,range(1995,2021),cache_path,'/Volumes/My Passport/Davids Stuff/pyblio_test3/'])\n",
    "#p3 = multiprocessing.Process(target = get_piis, args = [term_list,df3,range(1995,2021),cache_path,'/Volumes/My Passport/Davids Stuff/pyblio_test2/'])\n",
    "#p4 = multiprocessing.Process(target = get_piis, args = [term_list,df4,range(1995,2021),cache_path,'/Volumes/My Passport/Davids Stuff/pyblio_test2/'])\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "#p3.start()\n",
    "#p4.start()\n",
    "\n",
    "# starttime=time.time()\n",
    "# while True:\n",
    "#     clear_cache(cache_path)\n",
    "#     clear_output()\n",
    "#     time.sleep(20.0 - ((time.time() - starttime) % 20.0)) \n",
    "\n",
    "p1.join()\n",
    "p2.join()\n",
    "#p3.join()\n",
    "#p4.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stuff below is for counting how many publications are located in an output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def absoluteFilePaths(directory):\n",
    "    for dirpath,_,filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            yield os.path.abspath(os.path.join(dirpath, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open('/Volumes/My Passport/Davids Stuff/pyblio_test/Gene: X/Gene: X.txt','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pubs(output_path):\n",
    "    count = 0\n",
    "    for path in absoluteFilePaths(output_path):\n",
    "        if 'txt' in path and '._' not in path:\n",
    "            file = open(path,'r')\n",
    "            #print(path)\n",
    "            a = sum([int(s) for s in string.split() if s.isdigit()])\n",
    "            count+=a\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_pubs('/Volumes/My Passport/Davids Stuff/pyblio_test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
